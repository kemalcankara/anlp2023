{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define sentences\n",
    "sentences = [\"Programming is a good habit\",\n",
    "            \"This is bad code you must improve it\",\n",
    "            \"This is a perfect idea\",\n",
    "            \"Your code was clean and neat\",\n",
    "            \"You are excellent programmer\",\n",
    "            \"You have performed badly in the examinations\",\n",
    "            \"You could have made it better\",\n",
    "            \"Good work! Keep it up.\",\n",
    "            \"Poor performance\",\n",
    "            \"Improve yourself\"]\n",
    "#define remarks\n",
    "remarks = array([1,0,1,1,1,0,0,1,0,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and one_hot_encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our approach involves breaking down each sentence into individual words and representing each sequence as a vector using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35, 39, 4, 44, 21], [47, 39, 8, 20, 37, 42, 40, 33], [47, 39, 4, 48, 22], [23, 20, 14, 46, 43, 48], [37, 25, 39, 44], [37, 27, 14, 36, 15, 23, 16], [37, 36, 27, 10, 33, 42], [44, 11, 49, 33, 39], [47, 9], [40, 28]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the sentences\n",
    "vocabulary_size = 50\n",
    "encoded_sequence = [ one_hot(s, vocabulary_size) for s in sentences ]\n",
    "print( encoded_sequence )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The function called \"one_hot\" will require a sentence and a vocabulary_size as input parameters. The code shown above will use the \"one_hot\" function imported from Keras to convert all the sentences into an encoded form consisting of integers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the one_hot function on the sentences, the above result is the output.\n",
    "\n",
    "But we can see that all the one_hot_encoded vectors are not of equal length, so to overcome this problem, we pad every sentence using the pad_sequences function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The belowe code will pad every sequence. Following is the output after applying the pad_sqeuences function on the one_hot_encoded vectors. We can see that every sequence has a length of ten numbers. \n",
    "\n",
    "Number of zeros added to each vector = max_length - length of one_hot_encoded vecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0 35 39  4 44 21]\n",
      " [ 0  0 47 39  8 20 37 42 40 33]\n",
      " [ 0  0  0  0  0 47 39  4 48 22]\n",
      " [ 0  0  0  0 23 20 14 46 43 48]\n",
      " [ 0  0  0  0  0  0 37 25 39 44]\n",
      " [ 0  0  0 37 27 14 36 15 23 16]\n",
      " [ 0  0  0  0 37 36 27 10 33 42]\n",
      " [ 0  0  0  0  0 44 11 49 33 39]\n",
      " [ 0  0  0  0  0  0  0  0 47  9]\n",
      " [ 0  0  0  0  0  0  0  0 40 28]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 10 words\n",
    "max_length = 10\n",
    "padded_sequence = pad_sequences( encoded_sequence, maxlen = max_length, padding='pre' )\n",
    "print( padded_sequence )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now we have created proper input data that we can feed to the embedding layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the code below we are creating embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 10)            500       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding( vocabulary_size, 10, input_length = max_length )\n",
    "model.add( embedding_layer )\n",
    "model.add( Flatten() )\n",
    "model.add( Dense(1, activation='sigmoid') )\n",
    "# compile the model\n",
    "model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "# summarize the model\n",
    "print( model.summary() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a sequential model. In the embedding layer, vocabulary_size is input_dim parameter, output_dim is set to 10, and input_length of the sequence is the length of the padded sequence (max_length), i.e., 10. After flattening it apply a dense layer using the sigmoid activation function. \n",
    "\n",
    "Compile the model using the adam optimizer and use the binary_crossentropy as a loss function. \n",
    "\n",
    "The summary of the model is displayed above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:51:08.597778: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# fit the model \n",
    "\n",
    "#The padded_sequence and remarks are then passed through this embedding layer. \n",
    "#Further accuracy of the model is evaluated\n",
    "model.fit( padded_sequence, remarks, epochs=50, verbose=0 )\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate( padded_sequence, remarks, verbose=0 )\n",
    "print( 'Accuracy: %f' % (accuracy*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
